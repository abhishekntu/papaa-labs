{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution on Multi-core CPUs\n",
    "\n",
    "When targeting CPUs, the set of possible optimizations and opportunities for parallelization are limited. You can exploit multiple cores and split your computations across those. You can exploit SIMD units in each core to further boost performance. If your CPU has an embedded GPU (for example, the Intel Iris graphics cores), it is sometimes possible to use the GPU through the OpenCL environment. These tightly-integrated GPUs share the memory space, and do not require explicit copying that is otherwise necessary for accelerators. A side benefit of using OpenCL here is the future possibility of porting to another, newer, OpenCL-compatible platform. \n",
    "\n",
    "We start as before, with the necessary PyOpenCL header declarations.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose platform:\n",
      "[0] <pyopencl.Platform 'Apple' at 0x7fff0000>\n",
      "Choice [0]:0\n",
      "Choose device(s):\n",
      "[0] <pyopencl.Device 'Intel(R) Core(TM) i5-6600 CPU @ 3.30GHz' on 'Apple' at 0xffffffff>\n",
      "[1] <pyopencl.Device 'AMD Radeon R9 M395 Compute Engine' on 'Apple' at 0x1021c00>\n",
      "Choice, comma-separated [0]:0\n",
      "Set the environment variable PYOPENCL_CTX='0:0' to avoid being asked again.\n"
     ]
    }
   ],
   "source": [
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5, 5)        # medium images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap\n",
    "\n",
    "#load the ipython extensions for pyopencl\n",
    "%load_ext pyopencl.ipython_ext\n",
    "\n",
    "from __future__ import absolute_import, print_function\n",
    "import pyopencl as cl\n",
    "\n",
    "ctx = cl.create_some_context(interactive=True)\n",
    "queue = cl.CommandQueue(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SIMD Vectorization:\n",
    "While most OpenCL compilers will auto-vectorize simple code, it is often necessary to explicitly use OpenCL vector types for ensuring high performance. This eliminates writing low-level intrinsics, and transparently allows the same OpenCL code to run on different hardware with varying SIMD vector widths. The **float4** type is an example of the OpenCL vector type. Apart from changing the type of your operation, you have to rearrnage your inputs to fit the vector access pattern. A 2D convolution rewritten for SIMD vectorization looks like one below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/pyopencl-2016.2-py3.5-macosx-10.11-x86_64.egg/pyopencl/cffi_cl.py:1456: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  \"to see more.\", CompilerWarning)\n"
     ]
    }
   ],
   "source": [
    "%%cl_kernel\n",
    "\n",
    "__kernel void convolve2D_vector(\n",
    "        __global float *in,               // W*H input images\n",
    "        __global float *filt,                 // K*K filter kernel\n",
    "        __global float *out)                    // W*H output images\n",
    "{\n",
    "        // get image resolution\n",
    "        int W = get_global_size(0);\n",
    "        int H = get_global_size(1);\n",
    "        int K = 3;\n",
    "\n",
    "        // get pixel position\n",
    "        int x = get_global_id(0); \n",
    "        int y = get_global_id(1);\n",
    "\n",
    "        float4 sum = 0; \n",
    "        int r=0, c=0, c4=0;\n",
    "        float* filt_ptr;\n",
    "        float* in_ptr;\n",
    "\n",
    "        // loop over rows\n",
    "        for (r = 0; r < K; r++) \n",
    "        {\n",
    "                // loop over columns\n",
    "                for(c = 0; c < K; c+=4)\n",
    "                {\n",
    "                        float4 filt4 = vload4(c4,filt_ptr);\n",
    "                        float4 in4 = vload4(c4,in_ptr);\n",
    "                        sum += filt4*in4;\n",
    "                        c4++;\n",
    "                        // vload4 requires const float* arguments! ugh!\n",
    "                        filt_ptr += r*K*sizeof(float);\n",
    "                        in_ptr += ((y+r)*W+x)*sizeof(float);\n",
    "                }\n",
    "                // TODO: for the odd last element..\n",
    "        }\n",
    "        out[y*W+x] = sum.x + sum.y + sum.z + sum.w;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above works well for large values of K>5. For smaller values of K<=5, we may want to avoid vectorization. We modified the loop over c, and replaced the inner portion of the loops with a vector operation. This does result in redundant data loads, but we expect (hope) caching helps reduce off-chip memory traffic. Vectorized loads are a more efficienct use of memory bandwidth as they permit coalesced access. We the run the code as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage, misc, signal;\n",
    "import numpy as np\n",
    "\n",
    "f = misc.ascent();\n",
    "in_np = f;\n",
    "\n",
    "filt_np = np.array([[1,2,1],[2,4,2],[1,2,1]]);\n",
    "\n",
    "mf = cl.mem_flags\n",
    "in_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=in_np)\n",
    "filt_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=filt_np)\n",
    "out_g = cl.Buffer(ctx, mf.WRITE_ONLY, in_np.nbytes)\n",
    "\n",
    "# Run OpenCL convolve2D function\n",
    "print(in_np.shape);\n",
    "convolve2D_vector(queue, in_np.shape, None, in_g, filt_g, out_g)\n",
    "\n",
    "out_np = np.empty_like(in_np)\n",
    "cl.enqueue_copy(queue, out_np, out_g)\n",
    "\n",
    "fig, (a, b) = plt.subplots(1, 2)\n",
    "a.imshow(in_np, cmap='gray')\n",
    "b.imshow(out_np, cmap='gray')\n",
    "plt.show() # apparently, plt.show() works than fig.show() in juypter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loop Unrolling:\n",
    "We can also use loop unrolling as a way to improve performance. Loops, without extra information, are sequential operations. If the programmer (or compiler) can reason about data independence across loop iterations, we can run each loop iteration in parallel. A programmer can provide hints to the compiler about what loop to unroll and to what extent. We first show a simple manually unrolled OpenCL kernel, and its equivalent version with compiler hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cl_kernel\n",
    "\n",
    "__kernel void convolve2D_unroll(\n",
    "        const __global float *in,               // W*H input images\n",
    "        __constant float *filt,                 // K*K filter kernel\n",
    "        __global float *out)                    // W*H output images\n",
    "{\n",
    "        // get image resolution\n",
    "        const int W = get_global_size(0);\n",
    "        const int H = get_global_size(1);\n",
    "        const int K = 3;\n",
    "\n",
    "        // get pixel position\n",
    "        const int x = get_global_id(0); \n",
    "        const int y = get_global_id(1);\n",
    "\n",
    "        float sum = 0;\n",
    "        int c = 0;\n",
    "\n",
    "        // loop over rows\n",
    "        for (int r = 0, r < K, r++)\n",
    "        {\n",
    "                // loop over columns\n",
    "                // only in OpenCL 2.0 __attribute__ ((opencl unroll hint(2)))\n",
    "                for(c = 0, c < K, c+=2)\n",
    "                {\n",
    "                        // manually unrolled\n",
    "                        sum += filt[r*K+c]*in[((y+r)*W+x)+c];\n",
    "                        sum += filt[r*K+c+1]*in[((y+r)*W+x)+c+1];\n",
    "                }\n",
    "        }\n",
    "        out[y*W+x] = sum + pBias;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the code blocks above we have a choice of (1) verbose, manual operation of unrolling, or (2) automated compiler-driven option. Which one would you choose? We run the code as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e25e427330cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfilt_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0min_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOPY_HOST_PTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhostbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfilt_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOPY_HOST_PTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhostbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilt_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cl' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage, misc, signal;\n",
    "import numpy as np\n",
    "\n",
    "f = misc.ascent();\n",
    "in_np = f;\n",
    "\n",
    "filt_np = np.array([[1,2,1],[2,4,2],[1,2,1]]);\n",
    "\n",
    "mf = cl.mem_flags\n",
    "in_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=in_np)\n",
    "filt_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=filt_np)\n",
    "out_g = cl.Buffer(ctx, mf.WRITE_ONLY, in_np.nbytes)\n",
    "\n",
    "# Run OpenCL convolve2D function\n",
    "print(in_np.shape);\n",
    "convolve2D_unroll(queue, in_np.shape, None, in_g, filt_g, out_g)\n",
    "\n",
    "out_np = np.empty_like(in_np)\n",
    "cl.enqueue_copy(queue, out_np, out_g)\n",
    "\n",
    "fig, (a, b) = plt.subplots(1, 2)\n",
    "a.imshow(in_np, cmap='gray')\n",
    "b.imshow(out_np, cmap='gray')\n",
    "plt.show() # apparently, plt.show() works than fig.show() in juypter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Thread-Level Parallelism\n",
    "The final aspect of performance tuning is parallelization across cores. This is not direct or explicit under OpenCL, but can be configured by careful selection of **global** and **local** workgroup sizes. When they're equal, all work items are scheduled onto a single core. The ratio between these workgroup sizes indicates the number of threads/cores you can target. The OpenCL runtime can also be configured through **Device Fission** settings to partition the OpenCL device and restrict OpenCL operations onto a subset of available threads/cores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
