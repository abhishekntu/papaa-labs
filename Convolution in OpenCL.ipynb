{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2DConvolution in OpenCL\n",
    "We can convert the C++ description of 2D convolution into OpenCL in a realtive straightforward manner. This requires splitting the code into two files -- a host file, and a kernel file. While this separation may seem forced, it naturally fits the **offload** model where the compute intensive portions of your application are moved to the accelerator. In our case, the nested for loops must be moved to the accelerator.\n",
    "\n",
    "Writing kernel code in OpenCL requires a different way of thinking about computation. The kernel file for 2D convolution captures the operations that must be performed at a single pixel. This idea is important -- by only specifying the per-pixel computation in the kernel, we are relying on the OpenCL compiler and runtime to transform our code automatically to parallelize most effectively on the accelerator. This is also the reason behind OpenCL's platform portability claim. We're using PyOpenCL, which provides a convenient front-end to the execution of the code on CPUs, GPUs and FPGAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeled on github.com/BLVC/caffe.git\n",
    "\n",
    "# magic function to import numpy, matplotlib, etc in jupyter notebook\n",
    "from pylab import * \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (5, 5)        # medium images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap\n",
    "\n",
    "from scipy import ndimage, misc, signal;\n",
    "\n",
    "kernel_str = \"\"\"__kernel void convolve2D(\n",
    "    __global float *in,     // W*H input images\n",
    "    __constant float *filt, // K*K filter kernel\n",
    "    __global float *out,    // W*H output images\n",
    "    int K,                  // filter resolution\n",
    "    float pBias)            // constant offset/bias\n",
    "{\n",
    "    // get pixel position\n",
    "    int W = get_global_size(0);\n",
    "    int H = get_global_size(1);\n",
    "\n",
    "    // get image resolution\n",
    "    int x = get_global_id(0); \n",
    "    int y = get_global_id(1);\n",
    "\n",
    "    float sum = 0;\n",
    "    int r = 0, c = 0;\n",
    "\n",
    "    // loop over kernel rows\n",
    "    for (r = 0; r < K; r++) {\n",
    "        // loop over kernel columns\n",
    "        for(c = 0; c < K; c++) {\n",
    "            sum += filt[r*K+c]*in[((y+r)*W+x)+c];\n",
    "        }\n",
    "    }\n",
    "    out[y*W+x] = sum + pBias;\n",
    "}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **convolve2D** OpenCL kernel code, we observe a few new portions. \n",
    "1. The **get_global_size** method is used to decide the image resolution $W$x$H$. \n",
    "2. The **get_global_id** is crucial to identify the $x$,$y$ position of the current pixel being processed. The concept of global ids is important. The OpenCL runtime will take this kernel and parallelize it across the global workgroup. Each workitem in the workgroup will have a unique global id. For this application, it represents the pixel position $x$,$y$. \n",
    "3. The nested for loops over the rows and columns of the image are gone! Only the loops over the kernels are left. This is tied to the idea of global workgroup size. When we set the global workgroup size to $W$x$H$, the OpenCL compiler automatically implicitly introduces the nested for loops over the image rows and columns for you. Additionally, the OpenCL runtime also parallelizes each pixel operation across the OpenCL device for you automatically. \n",
    "\n",
    "The workgroup is set in the host code which we discuss below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The host code in OpenCL often must be written to target a given platform. It looks ugly in C/C++ but its mostly structurally same across all applications. Hence, we're using PyOpenCL -- its simple, convenient, pretty and multi-platform.\n",
    "\n",
    "First, we must include the correct PyOpenCL headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "import numpy as np\n",
    "import pyopencl as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must setup the OpenCL platform. Again, the C++ implementation of this is not only ugly, its tedious, annoying, and error-prone. The Python-based structure is pretty broilerplate and with few modifications, you can use it for other applications. There is also extensive error checking done in the PyOpenCL libary on your behalf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be string, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9557d0b85b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYOPENCL_COMPILER_OUTPUT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/os.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, item)\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                 \u001b[0mputenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be string, not int"
     ]
    }
   ],
   "source": [
    "ctx = cl.create_some_context(interactive=True)\n",
    "queue = cl.CommandQueue(ctx)\n",
    "\n",
    "import os\n",
    "os.environ['PYOPENCL_COMPILER_OUTPUT']=1;\n",
    "prg = cl.Program(ctx, kernel_str).build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the OpenCL objects have been created, kernels compiled, devices detected and targeted, we can proceed to the real meat of the code. Here, we allocate **host** and **device** memory structures. This step is important to understand. The offload model uses the accelerator to speedup portions of the code that are bottleneck in your application. When you offload, you need to copy over the data that the accelerator needs to access. This is an artifcact of the separation of memory spaces of the accelerator and host. In future OpenCL releases, this might go away as memory spaces can be unified. Some recent NVIDIA GPUs unify the spaces already. \n",
    "\n",
    "The device memories are allocated using **cl.Buffer** which is similar to **malloc** on the host. There are fancy tags that provide more information to the OpenCL compiler to optimize storage of the device arrays. \n",
    "\n",
    "We then come to the key OpenCL function **clEnqueueNDRangeKernel** which is implicitly run as **prg.convolve2d**. This is used to run your kernel in parallel on the accelerator. \n",
    "\n",
    "There are two arguments to the call after *queue* which are the **global** and **local** workgroup sizes. These numbers are used by the compiler/runtime to auto-parallelize the kernel code across all work items. For our case the **global** workgroup size is $W$x$H$ (or **in_np.shape**) to reflect the resolution of the image. We process each pixel independently in each OpenCL workitem. The **local** workgroup size is an optional hint that suggests how many workitems to pack into an OpenCL **Compute Unit**. For this example, this doesn't really matter so much, but this can be used to optimize performance when data sharing is concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage, misc, signal;\n",
    "\n",
    "f = misc.ascent();\n",
    "in_np = f;\n",
    "\n",
    "filt = np.array([[1,2,1],\n",
    "...              [2,4,2],\n",
    "...              [1,2,1]]);\n",
    "\n",
    "mf = cl.mem_flags\n",
    "in_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=in_np)\n",
    "filt_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=filt_np)\n",
    "out_g = cl.Buffer(ctx, mf.WRITE_ONLY, in_np.nbytes)\n",
    "\n",
    "prg.convolve2D(queue, in_np.shape, None, in_g, filt_g, 3, out_g)\n",
    "\n",
    "out_np = np.empty_like(in_np)\n",
    "cl.enqueue_copy(queue, out_np, out_g)\n",
    "\n",
    "fig, (a, b) = plt.subplots(1, 2)\n",
    "a.imshow(f, cmap='gray')\n",
    "b.imshow(out, cmap='gray')\n",
    "plt.show() # apparently, plt.show() works than fig.show() in juypter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
