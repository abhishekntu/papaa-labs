{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2DConvolution in OpenCL\n",
    "We can convert the C++ description of 2D convolution into OpenCL in a realtive straightforward manner. This requires splitting the code into two files -- a host file, and a kernel file. While this separation may seem forced, it naturally fits the **offload** model where the compute intensive portions of your application are moved to the accelerator. In our case, the nested for loops must be moved to the accelerator.\n",
    "\n",
    "Writing kernel code in OpenCL requires a different way of thinking about computation. The kernel file for 2D convolution captures the operations that must be performed at a single pixel. This idea is important -- by only specifying the per-pixel computation in the kernel, we are relying on the OpenCL compiler and runtime to transform our code automatically to parallelize most effectively on the accelerator. This is also the reason behind OpenCL's platform portability claim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__kernel void convolve2D(\n",
    "    __global float *in,     // W*H input images\n",
    "    __constant float *filt, // K*K filter kernel\n",
    "    __global float *out,    // W*H output images\n",
    "    int K,                  // filter resolution\n",
    "    float pBias)            // constant offset/bias\n",
    "{\n",
    "    // get pixel position\n",
    "    int W = get_global_size(0);\n",
    "    int H = get_global_size(1);\n",
    "\n",
    "    // get image resolution\n",
    "    int x = get_global_id(0); \n",
    "    int y = get_global_id(1);\n",
    "\n",
    "    float sum = 0;\n",
    "    int c = 0;\n",
    "\n",
    "    // loop over kernel rows\n",
    "    for (int r = 0, r < K, r++) {\n",
    "        // loop over kernel columns\n",
    "        for(c = 0, c < K, c++) {\n",
    "            sum += filt[r*K+c]*in[((y+r)*W+x)+c];\n",
    "        }\n",
    "    }\n",
    "    out[y*W+x] = sum + pBias;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **convolve2D** OpenCL kernel code, we observe a few new portions. \n",
    "1. The **get_global_size** method is used to decide the image resolution $W$x$H$. \n",
    "2. The **get_global_id** is crucial to identify the $x$,$y$ position of the current pixel being processed. The concept of global ids is important. The OpenCL runtime will take this kernel and parallelize it across the global workgroup. Each workitem in the workgroup will have a unique global id. For this application, it represents the pixel position $x$,$y$. \n",
    "3. The nested for loops over the rows and columns of the image are gone! Only the loops over the kernels are left. This is tied to the idea of global workgroup size. When we set the global workgroup size to $W$x$H$, the OpenCL compiler automatically implicitly introduces the nested for loops over the image rows and columns for you. Additionally, the OpenCL runtime also parallelizes each pixel operation across the OpenCL device for you automatically. \n",
    "\n",
    "The workgroup is set in the host code which we discuss below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The host code in OpenCL often must be written to target a given platform. It looks ugly in C/C++ but its mostly structurally same across all applications. We can break it down into the key building blocks listed below. With some differences, most applications will use this model.\n",
    "\n",
    "First, we must include the correct OpenCL headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <CL/cl.h>\n",
    "#include <CL/cl_ext.h>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must setup the OpenCL platform. Look, this following piece of code is not only ugly, its tedious, and annoying. There are C++ and PyOpenCL flows that significantly clean this up, but for our FPGA backend, we still need to understand this process. Bear with us. The structure is pretty broilerplate and with few modifications, you can use it for other applications. There is also extensive error checking, a good practice, to help you debug what's going on... it inadvertently also makes this code longer than it needs to be. Newer revisions of OpenCL are moving towards simplifying this portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    // Allocate weird OpenCL structures\n",
    "    cl_event event,event1,event2;\n",
    "    cl_device_id device_id;             // compute device id \n",
    "    cl_context context;                 // compute context\n",
    "    cl_command_queue commands;          // compute command queue\n",
    "    cl_program program;                 // compute program\n",
    "    cl_kernel kernel[3];                // compute kernel\n",
    "\n",
    "    // Get number of OpenCL devices installed\n",
    "    cl_uint dev_cnt = 0;\n",
    "    clGetPlatformIDs(0, 0, &dev_cnt);\n",
    "    \n",
    "    // Get the list of platform identifiers\n",
    "    cl_platform_id platform_ids[5];\n",
    "\n",
    "    // Check type of device you want to target\n",
    "    clGetPlatformIDs(dev_cnt, platform_ids, NULL);\n",
    "    for(i=0;i<dev_cnt;i++) {\n",
    "#ifdef DEVICE_GPU\n",
    "        err = clGetDeviceIDs(platform_ids[i], CL_DEVICE_TYPE_GPU, 1, &device_id, NULL);\n",
    "#else\n",
    "        err = clGetDeviceIDs(platform_ids[i], CL_DEVICE_TYPE_CPU, 1, &device_id, NULL);\n",
    "#endif\n",
    "        if(err == CL_SUCCESS)\n",
    "            break;\n",
    "    }\n",
    "    \n",
    "    if (err != CL_SUCCESS) {\n",
    "            if(err == CL_INVALID_PLATFORM)\n",
    "                    printf(\"CL_INVALID_PLATFORM\\n\");\n",
    "            if(err == CL_INVALID_DEVICE_TYPE)\n",
    "                    printf(\"CL_INVALID_DEVICE_TYPE\\n\");\n",
    "            if(err == CL_INVALID_VALUE)\n",
    "                    printf(\"CL_INVALID_VALUE\\n\");\n",
    "            if(err == CL_DEVICE_NOT_FOUND)\n",
    "                    printf(\"CL_DEVICE_NOT_FOUND\\n\");\n",
    "            printf(\"Error: Failed to clGetDeviceIDs!\\n\");\n",
    "            return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    // Create a compute context \n",
    "    context = clCreateContext(0, 1, &device_id, NULL, NULL, &err);\n",
    "    if (!context) {\n",
    "            printf(\"Error: Failed clCreateContext!\\n\");\n",
    "            return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "     // Create a command commands\n",
    "     commands = clCreateCommandQueue(context, device_id, CL_QUEUE_PROFILING_ENABLE, &err);\n",
    "     if (!commands) {\n",
    "            printf(\"Error: Failed clCreateCommandQueue!\\n\");\n",
    "            return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    // Read in the source file as a string. Yuck!\n",
    "    char *kern_src;\n",
    "    long kern_size;\n",
    "    kern_size = LoadOpenCLKernel(\"simple.cl\", &kern_src);\n",
    "    if( kern_ize < 0L ) {\n",
    "        perror(\"File read failed\");\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    // Create OpenCL object to hold the program source\n",
    "    program = clCreateProgramWithSource(context, 1, (const char **) & kern_src, NULL, &err);\n",
    "    if (!program) {\n",
    "        printf(\"Error: Failed clCreateProgramWithSource!\\n\");\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    // Compile the OpenCL kernel you've just read\n",
    "    err = clBuildProgram(program, 0, NULL, NULL, NULL, NULL);\n",
    "    if (err != CL_SUCCESS) {\n",
    "            size_t len;\n",
    "            char buf[2048];\n",
    "            printf(\"Error: Failed clBuildProgram!\\n\");\n",
    "            clGetProgramBuildInfo(program, device_id, CL_PROGRAM_BUILD_LOG, sizeof(buf), buf, &len);\n",
    "            printf(\"%s\\n\", buf);\n",
    "            exit(1);\n",
    "    }\n",
    "\n",
    "    // Create the executable OpenCL kernel \n",
    "    kernel[0] = clCreateKernel(program, \"convolve\", &err);\n",
    "    if (!kernel[0] || err != CL_SUCCESS) {\n",
    "            printf(\"Error: Failed clCreateKernel!\\n\");\n",
    "            exit(1);\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an experiment -- here's the same code without error checking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    // Allocate weird OpenCL structures\n",
    "    cl_event event,event1,event2;\n",
    "    cl_device_id device_id;             // compute device id \n",
    "    cl_context context;                 // compute context\n",
    "    cl_command_queue commands;          // compute command queue\n",
    "    cl_program program;                 // compute program\n",
    "    cl_kernel kernel[3];                // compute kernel\n",
    "\n",
    "    // Get number of OpenCL devices installed\n",
    "    err = clGetDeviceIDs(platform_ids[i], CL_DEVICE_TYPE_GPU, 1, &device_id, NULL);\n",
    "    \n",
    "    // Create a compute context \n",
    "    context = clCreateContext(0, 1, &device_id, NULL, NULL, &err);\n",
    "\n",
    "    // Create a command commands\n",
    "    commands = clCreateCommandQueue(context, device_id, CL_QUEUE_PROFILING_ENABLE, &err);\n",
    "\n",
    "    // Read in the source file as a string. Yuck!\n",
    "    char *kern_src;\n",
    "    LoadOpenCLKernel(\"simple.cl\", &kern_src);\n",
    "\n",
    "    // Create OpenCL object to hold the program source\n",
    "    program = clCreateProgramWithSource(context, 1, (const char **) & kern_src, NULL, &err);\n",
    "\n",
    "    // Compile the OpenCL kernel you've just read\n",
    "    err = clBuildProgram(program, 0, NULL, NULL, NULL, NULL);\n",
    "\n",
    "    // Create the executable OpenCL kernel \n",
    "    kernel[0] = clCreateKernel(program, \"convolve\", &err);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the OpenCL objects have been created, kernels compiled, devices detected and targeted, we can proceed to the real meat of the code. Here, we allocated **host** and **device** memory structures. This step is important to understand. The offload model uses the accelerator to speedup portions of the code that are bottleneck in your application. When you offload, you need to copy over the data that the accelerator needs to access. This is an artifcact of the separation of memory spaces of the accelerator and host. In future OpenCL releases, this might go away as memory spaces can be unified. Some recent NVIDIA GPUs unify the spaces already. \n",
    "\n",
    "The device memories are allocated using **clCreateBuffer** which is similar to **malloc** on the host. There are fancy tags that provide more information to the OpenCL compiler to optimize storage of the device arrays. \n",
    "\n",
    "You also need to build the list of kernel arugments using **clSetKernelArg**. This is exhausting! CUDA looks so much simpler -- but the pain is worth it, and as we mentioned earlier, this only has to be done once.\n",
    "\n",
    "We then come to the key OpenCL function **clEnqueueNDRangeKernel**. This is used to run your kernel in parallel on the accelerator. You may have noticed the **localWorkSize** and **globalWorkSize** structures -- these are used by the compiler/runtime to auto-parallelize the kernel code across all work items. For our case the **globalWorkSize** is $W$x$H$ to reflect the resolution of the image. We process each pixel independently in each OpenCL workitem. The **localWorkSize** is an optional hint that suggests how many workitems to pack into an OpenCL **Compute Unit**. For this example, this doesn't really matter so much, but this can be used to optimize performance when data sharing is concerned.\n",
    "\n",
    "We record OpenCL runtime using the **clGetEventProfilingInfo** API. This is useful to help us determine the performance of our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    // Read input image and initialize host arrays\n",
    "    pgm_t input_pgm;\n",
    "    readPGM(&input_pgm,\"donald_duck_in.pgm\");\n",
    "    int W = input_pgm.width;\n",
    "    int H = input_pgm.height;\n",
    "\n",
    "    printf(\"cl:main input image resolution:%dx%d\\n\", W, H);\n",
    "\n",
    "    // Host memory for images, kernels\n",
    "    float  *h_input, *h_output, *h_kernel;\n",
    "    \n",
    "    // Allocate host memory for matrices\n",
    "    h_input = (float*)malloc(sizeof(float) * W * H);\n",
    "    h_kernel = (float*)malloc(sizeof(float) * K * K);\n",
    "    h_output = (float*)malloc(sizeof(float) * W * H);\n",
    "    int bias = 1;\n",
    "        \n",
    "    // OpenCL device memory for matrices\n",
    "    cl_mem d_input, d_output, d_kernel;    \n",
    "    \n",
    "    // create OpenCL device buffers\n",
    "    d_image  = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, W*H, h_input, &err);\n",
    "    d_kernel = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, K*K, h_kernel, &err);\n",
    "    d_output = clCreateBuffer(context, CL_MEM_WRITE_ONLY , W*H, NULL, &err);\n",
    "    \n",
    "    if (!d_image || !d_filter || !d_output) {\n",
    "        printf(\"Error: Failed clCreateBuffer!\\n\");\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    cl_ulong time_start, time_end;\n",
    "    double total_time,itime;\n",
    "\n",
    "    // Launch OpenCL kernel\n",
    "    size_t localWorkSize[2], globalWorkSize[2];\n",
    "\n",
    "    // set OpenCL kernel arguments\n",
    "    err  = clSetKernelArg(kernel[0], 0, sizeof(cl_mem), (void *)&d_input);\n",
    "    err |= clSetKernelArg(kernel[0], 1, sizeof(cl_mem), (void *)&d_kernel);\n",
    "    err |= clSetKernelArg(kernel[0], 2, sizeof(cl_mem), (void *)&d_output);\n",
    "    err |= clSetKernelArg(kernel[0], 3, sizeof(int), (void *)&K);\n",
    "    err |= clSetKernelArg(kernel[0], 4, sizeof(cl_mem), (void*)&bias);\n",
    "\n",
    "    if (err != CL_SUCCESS) {\n",
    "        printf(\"Error: Failed clSetKernelArg! %d\\n\", err);\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "    \n",
    "    // local workgroup size sets pixels per compute unit.\n",
    "    localWorkSize[0] = 2;\n",
    "    localWorkSize[1] = 2;\n",
    "\n",
    "    // global workgroup size sets total work\n",
    "    globalWorkSize[0] = W;\n",
    "    globalWorkSize[1] = H;\n",
    "    \n",
    "    // Enqueue task for parallel execution\n",
    "    clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_START, sizeof(time_start), &time_start, NULL);\n",
    "    err = clEnqueueNDRangeKernel(commands, kernel[0], 2, NULL, globalWorkSize, localWorkSize, 0, NULL, &event);\n",
    "    if (err != CL_SUCCESS){\n",
    "        if(err == CL_INVALID_WORK_ITEM_SIZE)\n",
    "            printf(\"CL_INVALID_WORK_ITEM_SIZE \\n\");\n",
    "        if(err == CL_INVALID_WORK_GROUP_SIZE)\n",
    "            printf(\"CL_INVALID_WORK_GROUP_SIZE \\n\");\n",
    "        printf(\"Error: Failed to execute kernel! %d\\n\", err);\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "    \n",
    "    clWaitForEvents(1,&event);\n",
    "    clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_END, sizeof(time_end), &time_end, NULL);\n",
    "        \n",
    "    // Retrieve result from device\n",
    "    err = clEnqueueReadBuffer(commands, d_output, CL_TRUE, 0, mem_size_output, h_output, 0, NULL, NULL);\n",
    "    if (err != CL_SUCCESS) {\n",
    "        printf(\"Error: Failed clEnqueueReadBuffer! %d\\n\", err);\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    pgm output_pgm;\n",
    "    output_pgm.width = W;\n",
    "    output_pgm.height = H;\n",
    "    normalizeF2PGM(&output_pgm, h_output);\n",
    "    writePGM(&output_pgm,\"donald_duck_out.pgm\");\n",
    "\n",
    "    printf(\"cl:main timing %0.3f us\\n\", total_time / 1000.0);\n",
    "\n",
    "    // Free memory and OpenCL objects\n",
    "    destroyPGM(&input_pgm);\n",
    "    destroyPGM(&output_pgm);\n",
    "    free(h_input);\n",
    "    free(h_output);\n",
    "    clReleaseMemObject(d_input);\n",
    "    clReleaseMemObject(d_output);\n",
    "    clReleaseMemObject(d_kernel);\n",
    "    clReleaseProgram(program);\n",
    "    clReleaseKernel(kernel[0]);\n",
    "    clReleaseCommandQueue(commands);\n",
    "    clReleaseContext(context);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
