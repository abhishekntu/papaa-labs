{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2DConvolution in OpenCL\n",
    "We can convert the C++ description of 2D convolution into OpenCL in a realtive straightforward manner. This requires splitting the code into two files -- a host file, and a kernel file. While this separation may seem forced, it naturally fits the **offload** model where the compute intensive portions of your application are moved to the accelerator. In our case, the nested for loops must be moved to the accelerator.\n",
    "\n",
    "Writing kernel code in OpenCL requires a different way of thinking about computation. The kernel file for 2D convolution captures the operations that must be performed at a single pixel. This idea is important -- by only specifying the per-pixel computation in the kernel, we are relying on the OpenCL compiler and runtime to transform our code automatically to parallelize most effectively on the accelerator. This is also the reason behind OpenCL's platform portability claim. We're using PyOpenCL, which provides a convenient front-end to the execution of the code on CPUs, GPUs and FPGAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modeled on github.com/BLVC/caffe.git\n",
    "\n",
    "# magic function to import numpy, matplotlib, etc in jupyter notebook\n",
    "from pylab import * \n",
    "from scipy import ndimage, misc, signal;\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (5, 5)        # medium images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap\n",
    "\n",
    "#load the ipython extensions for pyopencl\n",
    "%load_ext pyopencl.ipython_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The host code in OpenCL often must be written to target a given platform. It looks ugly in C/C++ but its mostly structurally same across all applications. Hence, we're using PyOpenCL -- its simple, convenient, pretty and multi-platform.\n",
    "\n",
    "First, we must include the correct PyOpenCL headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "import numpy as np\n",
    "import pyopencl as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must setup the OpenCL platform. Again, the C++ implementation of this is not only ugly, its tedious, annoying, and error-prone. The Python-based structure is pretty broilerplate and with few modifications, you can use it for other applications. There is also extensive error checking done in the PyOpenCL libary on your behalf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose platform:\n",
      "[0] <pyopencl.Platform 'Apple' at 0x7fff0000>\n",
      "Choice [0]:0\n",
      "Choose device(s):\n",
      "[0] <pyopencl.Device 'Intel(R) Core(TM) i5-6600 CPU @ 3.30GHz' on 'Apple' at 0xffffffff>\n",
      "[1] <pyopencl.Device 'AMD Radeon R9 M395 Compute Engine' on 'Apple' at 0x1021c00>\n",
      "Choice, comma-separated [0]:0\n",
      "Set the environment variable PYOPENCL_CTX='0:0' to avoid being asked again.\n"
     ]
    }
   ],
   "source": [
    "ctx = cl.create_some_context(interactive=True)\n",
    "queue = cl.CommandQueue(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/pyopencl-2016.2-py3.5-macosx-10.11-x86_64.egg/pyopencl/cffi_cl.py:1456: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  \"to see more.\", CompilerWarning)\n"
     ]
    }
   ],
   "source": [
    "%%cl_kernel \n",
    "__kernel void convolve2D(\n",
    "    __global float *in,     // W*H input images\n",
    "    __constant float *filt, // K*K filter kernel\n",
    "    __global float *out)    // W*H output images\n",
    "{\n",
    "    // get pixel position\n",
    "    int W = get_global_size(0);\n",
    "    int H = get_global_size(1);\n",
    "    int K = 3;\n",
    "    \n",
    "    // get image resolution\n",
    "    int x = get_global_id(0); \n",
    "    int y = get_global_id(1);\n",
    "\n",
    "    float sum = 0;\n",
    "    int r = 0, c = 0;\n",
    "\n",
    "    // loop over kernel rows\n",
    "    for (r = 0; r < K; r++) {\n",
    "        // loop over kernel columns\n",
    "        for(c = 0; c < K; c++) {\n",
    "            sum += filt[r*K+c]*in[((y+r)*W+x)+c];\n",
    "        }\n",
    "    }\n",
    "    out[y*W+x] = sum;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **convolve2D** OpenCL kernel code shown above, we observe a few new portions. \n",
    "1. The **get_global_size** method is used to decide the image resolution $W$x$H$. \n",
    "2. The **get_global_id** is crucial to identify the $x$,$y$ position of the current pixel being processed. The concept of global ids is important. The OpenCL runtime will take this kernel and parallelize it across the global workgroup. Each workitem in the workgroup will have a unique global id. For this application, it represents the pixel position $x$,$y$. \n",
    "3. The nested for loops over the rows and columns of the image are gone! Only the loops over the kernels are left. This is tied to the idea of global workgroup size. When we set the global workgroup size to $W$x$H$, the OpenCL compiler automatically implicitly introduces the nested for loops over the image rows and columns for you. Additionally, the OpenCL runtime also parallelizes each pixel operation across the OpenCL device for you automatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile the kernel into an OpenCL executable. This is done for you behind-the-scenes in Jupyter. But in PyOpenCL, you would run ```prg=cl.Program(ctx,code).build()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the OpenCL objects have been created, kernels compiled, devices detected and targeted, we can proceed to the real meat of the code. Here, we allocate **host** and **device** memory structures. This step is important to understand. The offload model uses the accelerator to speedup portions of the code that are bottleneck in your application. When you offload, you need to copy over the data that the accelerator needs to access. This is an artifcact of the separation of memory spaces of the accelerator and host. In future OpenCL releases, this might go away as memory spaces can be unified. Some recent NVIDIA GPUs unify the spaces already. \n",
    "\n",
    "The device memories are allocated using **cl.Buffer** which is similar to **malloc** on the host. There are fancy tags that provide more information to the OpenCL compiler to optimize storage of the device arrays. \n",
    "\n",
    "We then come to the key OpenCL function **clEnqueueNDRangeKernel** which is implicitly run as **prg.convolve2d**. This is used to run your kernel in parallel on the accelerator. \n",
    "\n",
    "There are two arguments to the call after *queue* which are the **global** and **local** workgroup sizes. These numbers are used by the compiler/runtime to auto-parallelize the kernel code across all work items. For our case the **global** workgroup size is $W$x$H$ (or **in_np.shape**) to reflect the resolution of the image. We process each pixel independently in each OpenCL workitem. The **local** workgroup size is an optional hint that suggests how many workitems to pack into an OpenCL **Compute Unit**. For this example, this doesn't really matter so much, but this can be used to optimize performance when data sharing is concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data can not convert to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-19ceaeefb49d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# apparently, plt.show() works than fig.show() in juypter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1810\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1811\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1812\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   4945\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   4946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4947\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4948\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    447\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    448\u001b[0m                 not np.can_cast(self._A.dtype, np.float)):\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data can not convert to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         if (self._A.ndim not in (2, 3) or\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data can not convert to float"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAE4CAYAAADFI0E4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11762c940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import ndimage, misc, signal;\n",
    "\n",
    "f = misc.ascent();\n",
    "in_np = f;\n",
    "\n",
    "filt_np = np.array([[1,2,1],[2,4,2],[1,2,1]]);\n",
    "\n",
    "mf = cl.mem_flags\n",
    "in_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=in_np)\n",
    "filt_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=filt_np)\n",
    "out_g = cl.Buffer(ctx, mf.WRITE_ONLY, in_np.nbytes)\n",
    "\n",
    "# Run OpenCL convolve2D function\n",
    "convolve2D(queue, in_np.shape, None, in_g, filt_g, out_g)\n",
    "\n",
    "out_np = np.empty_like(in_np)\n",
    "cl.enqueue_copy(queue, out_np, out_g)\n",
    "\n",
    "fig, (a, b) = plt.subplots(1, 2)\n",
    "a.imshow(in_g, cmap='gray')\n",
    "b.imshow(out_g, cmap='gray')\n",
    "plt.show() # apparently, plt.show() works than fig.show() in juypter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the same flow working through OpenCL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
